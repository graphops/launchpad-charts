{{/* In order to keep the looping in one place, this file contains all
       resources to be created for each group of Graph Nodes */}}

### Enabled Graph Node Groups:
{{- $indexPools := dict }}
{{- range $groupName, $groupValues := $.Values.graphNodeGroups }}
  {{- $values := mergeOverwrite dict $.Values.graphNodeDefaults $groupValues }}
  {{- if $values.enabled }}
    {{- print "# - " $groupName " (" $values.replicaCount " replicas)" | nindent 0 }}
    {{- range $indexPoolName := $values.includeInIndexPools }}
      {{- $indexPoolNodeIds := default list (get $indexPools $indexPoolName) }}
      {{- range $replicaNumber := until (int $values.replicaCount) }}
        {{- $nodeId := print (include "graph-node.fullname" $) "-" $groupName "-" $replicaNumber }}
        {{- $indexPoolNodeIds = append $indexPoolNodeIds $nodeId }}
      {{- end }}
      {{- $_ := set $indexPools $indexPoolName $indexPoolNodeIds }}
    {{- end }}
  {{- end }}
{{- end }}

{{- $generated := dict "indexPools" $indexPools }}
{{- $_ := set . "generated" $generated }}
### Generated Config Template Variables:
#{{ toYaml $generated | indent 1 | replace "\n" "\n#" }}

{{- range $groupName, $groupValues := $.Values.graphNodeGroups }}
{{- $values := mergeOverwrite dict $.Values.graphNodeDefaults $groupValues }}
{{- if $values.enabled }}
{{- $componentLabel := include "graph-node.componentLabelFor" $groupName }}
{{- $graphNodeConfigToml := print (tpl $values.config $) }}
{{/* The outer range seems to mess with the inner context and break helpers.
       The with below resets the inner context to the root ($) */}}
{{- with $ }}
{{/* START StatefulSet */}}
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ include "graph-node.fullname" . }}-{{ $groupName }}
  labels:
    {{- include "graph-node.labels" . | nindent 4 }}
    {{- $componentLabel | nindent 4 }}
spec:
  serviceName: {{ include "graph-node.fullname" . }}-{{ $groupName }}-headless
  replicas: {{ $values.replicaCount | default 1 }}
  podManagementPolicy: Parallel # https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#parallel-pod-management
  updateStrategy:
    type: RollingUpdate # https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
  selector:
    matchLabels:
      {{- include "graph-node.selectorLabels" . | nindent 6 }}
      {{- $componentLabel | nindent 6 }}
  template:
    metadata:
      annotations:
        checksum/config.toml: {{ $graphNodeConfigToml | sha256sum }}
      {{- with $values.podAnnotations }}
        {{- toYaml . | nindent 8 }}
      {{- end }}
      labels:
        {{- include "graph-node.selectorLabels" . | nindent 8 }}
        {{- $componentLabel | nindent 8 }}
    spec:
      {{- with $values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      serviceAccountName: {{ include "graph-node.serviceAccountName" . }}
      {{- with $values.podSecurityContext }}
      securityContext:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      terminationGracePeriodSeconds: {{ $values.terminationGracePeriodSeconds | default "60" }}
      volumes:
        - name: tmp # this is to provide a writable /tmp even with securityContext.readOnlyRootFilesystem=true
          emptyDir: {}
        - name: config
          configMap:
            # Provide the name of the ConfigMap you want to mount.
            name: {{ include "graph-node.fullname" . }}-{{ $groupName }}
      initContainers:
        - name: {{ $groupName }}-init
          image: busybox:stable
          imagePullPolicy: IfNotPresent
          command: ["sh", "-c", "set -ex; ulimit -n 65536; ulimit -a"]
          securityContext:
            privileged: true #Â required for ulimit change
      containers:
        - name: {{ $groupName }}
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          securityContext:
            readOnlyRootFilesystem: true
            capabilities:
              drop:
                - ALL
          command:
            - graph-node
            - --config=/config/config.toml
            {{- with $values.extraArgs }}
              {{- toYaml (. | default list) | nindent 12 }}
            {{- end }}
          {{- if (or $values.env $values.secretEnv) }}
          env:
            - name: NODE_ID
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
          {{- with $values.env }}
          {{- range $key, $val := .}}
            - name: {{ $key | quote }}
              value: {{ $val | quote }}
          {{- end }}
          {{- end }}
          {{- with $values.secretEnv }}
          {{- range $key, $val := .}}
            - name: {{ $key | quote }}
              valueFrom:
                secretKeyRef:
                  name: {{ $val.secretName | quote }}
                  key: {{ $val.key | quote }}
                  optional: false
          {{- end }}
          {{- end }}
          {{- end }}
          ports:
            - name: http-query
              containerPort: 8000
              protocol: TCP
            - name: http-queryws
              containerPort: 8001
              protocol: TCP
            - name: http-admin
              containerPort: 8020
              protocol: TCP
            - name: http-status
              containerPort: 8030
              protocol: TCP
            - name: http-metrics
              containerPort: 8040
              protocol: TCP
          volumeMounts:
          - name: config
            mountPath: "/config"
            readOnly: true
          readinessProbe:
            # This currently requires GRPCContainerProbe feature gate to be enabled on the kubelet
            # https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-a-grpc-liveness-probe
            # https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/
            grpc:
              port: 9090 # named ports not supported yet by grpc probes
          {{- with $values.resources }}
          resources:
            {{- toYaml . | nindent 12 }}
          {{- end }}
      {{- with $values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- if or $values.affinity $values.affinityPresets.antiAffinityByHostname }}
      affinity:
      {{- with $values.affinity }}
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- if $values.affinityPresets.antiAffinityByHostname }}
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                - key: app.kubernetes.io/instance
                  operator: In
                  values:
                  - {{ $.Release.Name }}
                - key: app.kubernetes.io/component
                  operator: In
                  values:
                  - {{ $groupName }}
              topologyKey: "kubernetes.io/hostname"
      {{- end }}
      {{- end }}
      {{- with $values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
{{/* END StatefulSet */}}
{{/* START ConfigMap */}}
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "graph-node.fullname" . }}-{{ $groupName }}
  labels:
    {{- include "graph-node.labels" . | nindent 4 }}
    {{- $componentLabel | nindent 4 }}
data:
  config.toml: |
    {{ $graphNodeConfigToml | nindent 4 }}

{{/* END ConfigMap */}}
{{/* START Services */}}
---
apiVersion: v1
kind: Service
metadata:
  name: {{ include "graph-node.fullname" . }}-{{ $groupName }}-headless
  labels:
    {{- include "graph-node.labels" . | nindent 4 }}
    {{- $componentLabel | nindent 4 }}
spec:
  clusterIP: None # Headless service
  ports:
  {{- range $portName, $portNumber := $values.service.ports }}
    - port: {{ $portNumber }} # the port we expose on the Service, user configurable
      targetPort: {{ $portName }} # the name of the port on the container that we are routing to
      protocol: TCP
      name: {{ $portName }}
  {{- end }}
  selector:
    {{- include "graph-node.selectorLabels" . | nindent 4 }}
    {{- $componentLabel | nindent 4 }}
---
apiVersion: v1
kind: Service
metadata:
  name: {{ include "graph-node.fullname" . }}-{{ $groupName }}
  labels:
    {{- include "graph-node.labels" . | nindent 4 }}
    {{- $componentLabel | nindent 4 }}
spec:
  type: {{ $values.service.type }}
  ports:
  {{- range $portName, $portNumber := $values.service.ports }}
    - port: {{ $portNumber }} # the port we expose on the Service, user configurable
      targetPort: {{ $portName }} # the name of the port on the container that we are routing to
      protocol: TCP
      name: {{ $portName }}
  {{- end }}
  selector:
    {{- include "graph-node.selectorLabels" . | nindent 4 }}
    {{- $componentLabel | nindent 4 }}
{{/* END Services */}}
{{/* START ServiceMonitor */}}
{{- if $.Values.prometheus.serviceMonitors.enabled }}
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: {{ include "graph-node.fullname" . }}-{{ $groupName }}
  labels:
    {{- include "graph-node.labels" . | nindent 4 }}
    {{- $componentLabel | nindent 4 }}
spec:
  jobLabel: "{{ .Release.Name }}"
  selector:
    matchLabels:
      {{- include "graph-node.selectorLabels" . | nindent 6 }}
      {{- $componentLabel | nindent 6 }}
  endpoints:
    - port: http-metrics
      {{- with .Values.prometheus.serviceMonitors.interval }}
      interval: {{ . }}
      {{- end }}
      {{- with .Values.prometheus.serviceMonitors.scrapeTimeout }}
      scrapeTimeout: {{ . }}
      {{- end }}
      honorLabels: true
      {{- if .Values.prometheus.serviceMonitors.relabelings }}
      relabelings:
      {{- toYaml .Values.prometheus.serviceMonitors.relabelings | nindent 8 }}
      {{- end }}
{{- end }}
{{- end }}
{{/* END ServiceMonitor */}}
{{- else }}
---
# {{ $groupName }} group of graph-nodes is not enabled
{{- end }}
{{- end }}